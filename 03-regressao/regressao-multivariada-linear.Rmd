---
title: "regressao linear multivariada"
author: "Nazareno Andrade"
output: 
  html_document:
    theme: readable
    fig_width: 7
    toc: true
    toc_float: true

---

```{r}
library(ggplot2)
theme_set(theme_bw())
library(GGally)
library(ggfortify)
library(broom)
require(ISLR)
library(dplyr)
library(tidyr)
library(modelr) # devtools::install_github("hadley/modelr")

```

# Os dados

```{r}
advertising = read.csv("data/Advertising.csv", row.names=1)

ggpairs(advertising, alpha = 0.7)
```

# Uma regressão linear simples 

Modelo da relação entre gasto com TV e vendas:

```{r}
advertising$TVsqrt = sqrt(advertising$TV)
tv.model = lm(Sales ~ TVsqrt, data = advertising)

tidy(tv.model, conf.int = TRUE)
glance(tv.model, conf.int = TRUE)

summary(tv.model)
```

```{r}
ggplot(advertising, aes(x = sqrt(TV), y = Sales)) + 
  geom_point(alpha = 0.4) + 
  geom_line(aes(y = predict(tv.model, advertising)), colour = "red")

autoplot(tv.model)

ggplot(advertising, aes(x = log(TV), y = log(Sales))) + 
  geom_point(alpha = 0.4)
```

Os resíduos dão sinal de não linearidade. Voltamos para falar de diagnóstico e consertos mais na frente.

# Colocando mais variáveis como preditoras

```{r}
radio.model = lm(Sales ~ Radio, data = advertising)
tidy(radio.model, conf.int = TRUE)
glance(radio.model, conf.int = TRUE)
```

```{r}
np.model = lm(Sales ~ Newspaper, data = advertising)
tidy(np.model, conf.int = TRUE)
glance(np.model, conf.int = TRUE)
```

Considerando os preditores ao mesmo tempo. Isso é diferente de considerá-los separadamente:

```{r}
multi = lm(Sales ~ TV + Newspaper + Radio, data = advertising)
tidy(multi, conf.int = TRUE)
glance(multi)
```

Repare na diferença nas significâncias dos preditores para os modelos univariados e para o multivariado.

Algumas perguntas que queremos responder: 

* O modelo considerando esses preditores é útil em explicar a resposta?
* Todos os preditores contribuem para explicar a resposta, ou apenas algum?
* Quão bem ajustado aos dados o modelo está?

# Interações não aditivas

# TODO como modelar interações quando espero que o efeito tenha sinais diferentes?

```{r}
multi = lm(Sales ~ TV + Radio + Radio*TV, data = advertising)
tidy(multi, conf.int = TRUE)
glance(multi)

autoplot(multi)

predict(multi, 
        data.frame(Radio = 10e3, TV = 20e3, Newspaper = 0), 
        interval = "predict")
```

# Preditores categóricos 

```{r}
mario <- read.csv("marioKart.txt", header = TRUE, sep = "\t")
str(mario)

ggpairs(select(mario, totalPr, cond, startPr, nBids))
mario <- filter(mario, totalPr < 100)

mlm <- lm(totalPr ~ cond, data = mario)
summary(mlm)

ggplot(mario, aes(x = cond, y = totalPr, group = 1)) + 
  geom_violin(aes(group = cond), alpha = 0.2) + 
  geom_point(position = position_jitter(width = 0.1), alpha = 0.6) + 
  geom_smooth(method = "lm", se = F)
```

Ambas juntas

```{r}
mlm <- lm(totalPr ~ startPr + cond, data = mario)
tidy(mlm, conf.int = TRUE)
glance(mlm)

library(tidyr)
library(modelr) # devtools::install_github("hadley/modelr")

m = mario %>% expand(startPr, cond)
grid = m %>% 
  add_predictions(totalPr = mlm)

ggplot(mario, aes(startPr, totalPr)) + 
  geom_point() + 
  facet_wrap(~cond) + 
  geom_line(data = grid, colour = "red", size = 1) 

autoplot(mlm)
```

```{r}
mlm <- lm(totalPr ~ shipSp, data = mario)
tidy(mlm, conf.int = TRUE)
glance(mlm)

m = mario %>% expand(startPr, cond)
grid = m %>% 
  add_predictions(totalPr = mlm)

ggplot(mario, aes(startPr, totalPr)) + 
  geom_point() + 
  facet_wrap(~cond) + 
  geom_line(data = grid, colour = "red", size = 1) 

autoplot(mlm)
```


# Problemas possíveis

1. Non-linearity of the response-predictor relationships. 
2. Correlation of error terms.
3. Non-constant variance of error terms.
4. Outliers.
5. High-leverage points.
6. Collinearity.

## Não linearidade na response-predictor relationship

### Caso 1

```{r}
auto = select(Auto, mpg, horsepower)
ggpairs(auto)
automodel = lm(mpg ~ horsepower, data = auto)
tidy(automodel, conf.int = TRUE)
glance(automodel)

m = auto %>% expand(horsepower)
grid = m %>% 
  add_predictions(mpg = automodel)

ggplot(auto, aes(horsepower, mpg)) + 
  geom_point(alpha = .8) + 
  geom_line(data = grid, colour = "red", size = 1) 

autoplot(automodel)
```

Uma solução possível é tentar polinômios de grau mais alto, que têm curva.

```{r}
ggpairs(auto)
automodel = lm(mpg ~ horsepower + I(horsepower^2), data = auto)

m = auto %>% expand(horsepower, horsepower^2)
grid = m %>% 
  add_predictions(mpg = automodel)

ggplot(auto, aes(horsepower, mpg)) + 
  geom_point(alpha = .8) + 
  geom_line(data = grid, colour = "red", size = 1) 

tidy(automodel)
glance(automodel)
autoplot(automodel)
```

### Caso 2:

(Na minha experiência, esse é mais comum)

```{r}
ggplot(diamonds, aes(x = carat, y = price)) +
  geom_point(alpha = .3)

caratmodel = lm(price ~ carat, data = diamonds)

m = diamonds %>% expand(carat)
grid = m %>% 
  add_predictions(price = caratmodel)

ggplot(diamonds, aes(carat, price)) + 
  geom_point(alpha = .1) + 
  geom_line(data = grid, colour = "red", size = 1) 

autoplot(caratmodel)
```

Solução: Transformar as variáveis para que elas passem a ter uma relação mais linear.

```{r}
ggplot(diamonds, aes(x = log(carat), y = log(price))) +
  geom_point(alpha = .2)

diamonds2 = data.frame(carat = log(diamonds$carat), 
                       price = log(diamonds$price))

caratmodel = lm(price ~ carat, data = diamonds2)

m = diamonds2 %>% expand(carat)
grid = m %>% 
  add_predictions(price = caratmodel)

ggplot(diamonds2, aes(carat, price)) + 
  geom_point(alpha = .1) + 
  geom_line(data = grid, colour = "blue", size = 1) 

autoplot(caratmodel)
```

As transformações mais comuns a considerar são log(x), sqrt(x), exp(x) e x^2.

##  Non-constant variance of error terms

Transformações ou weighted least squares. 

```{r}
advertising = read.csv("data/Advertising.csv", row.names=1)
ggpairs(advertising)

tv.model = lm(Sales ~ TV, data = advertising)

tidy(tv.model, conf.int = TRUE)
glance(tv.model, conf.int = TRUE)

autoplot(tv.model)

ggplot(advertising, aes((TV), (Sales))) + 
  geom_point()

ggplot(advertising, aes(log(TV), log(Sales))) + 
  geom_point()

tv.model2 = lm(log(Sales) ~ log(TV), data = advertising)

tidy(tv.model, conf.int = TRUE)
glance(tv.model, conf.int = TRUE)

autoplot(tv.model2)

```


## Outliers e High-leverage points

![outliers](others-figs//3.12.pdf)

![leverage](others-figs//3.13.pdf)

Uma boa: http://setosa.io/ev/ordinary-least-squares-regression/

No plot de studentized residuals, pontos com resíduos normalizados maiores que 3 são suspeitos.

Para leverage, o adequado é olhar pontos com leverage muito acima dos demais, ou maior que (p + 1)/n. (p sendo o número de preditores.)

## Colinearity

![colinearidade](others-figs//3.14.pdf)

Recomendação: VIF < 5 ou VIF < 10

```{r}
library(car)
vif(multi)
vif(mlm)
```

```{r}
credit <- read.csv("data/Credit.csv", row.names=1)
names(credit)
credit.model = lm(Balance ~ Age + Rating + Limit, data = credit)
summary(credit.model)

credit.model = lm(Balance ~ Age + Limit, data = credit)

vif(credit.model)
cor(credit %>% select(Age, Rating, Limit))
```

